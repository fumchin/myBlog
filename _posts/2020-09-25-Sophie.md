---
layout: single
title: 論文筆記：SoPhie - An Attentive GAN for Predicting Paths Compliant to Social and Physical Constraints
excerpt: YAmir Sadeghian, Vineet Kosaraju, Ali Sadeghian, Noriaki Hirose, S. Hamid Rezatofighi, Silvio Savarese
categories:
    - Paper
author_profile: true
classes: wide
---

## 前言
論文連結：[SoPhie：An Attentive GAN for Predicting Paths Compliant to Social and Physical Constraints](https://arxiv.org/pdf/1806.01482.pdf)  
會議：CVPR 2019  
這篇paper是蠻久以前看的，就大概紀錄一下><

## Introduction
先來看一下他的主要貢獻：  
> Main Contributions
> 1. Use scene context information jointly with social interaction
> 2. More reliable feature extraction
> 3. Attention mechanism(*2) + LSTM based GAN
> 4. Multiple trajectory forecasting benchmarks

比較特別的地方應該就是他會將一整個場景的照片丟進去，提取出場景的資訊，找出哪裡可能有障礙物，哪邊可能是場景中可行的路線。再將這些資訊結合agent之間的互動特徵出預測的路徑。

## Related Work
這篇用到了CNN（VGG-19）、Attention和GAN，下面會簡單介紹一下。  
（有空再打哈哈哈）

## Method
### Problem Definition
* 我們的問題是啥勒？
![problem_definition](https://raw.githubusercontent.com/fumchin/myblog/master/assets/images/post_images/papers/Sophie/problem_definition.png)  
X：（1）～（t）的觀測位置資訊  
Y：時間（t+1） ~ （t+T）的真實位置（ground truth）  
Y with小帽帽：時間（t+1） ~ （t+T）的預測位置  
圖上第三行的意思就是把這些丟進去，就會蹦出解答這樣。

### Overall Model
* 先來看個圖圖，我把paper中提到的三大架構一起畫上去了。
![model](https://raw.githubusercontent.com/fumchin/myblog/master/assets/images/post_images/papers/Sophie/model.png)
> Q：阿是那三大？又分別在幹麻？  
> A：
 1. **feature extractor module（特徵萃取）**：分成上下兩部份。
>   * 上半部：利用CNN提取場景的特徵（障礙物、可以走的路徑等等）。
>   * 下半部：提取agent的特徵（包含自己路徑的特徵以及互動所得的特徵）。
> 2. **attention module （注意力）**：分成兩種attention。
>   * physical attention：學習場景中誰是障礙物，然後嘗試將注意力集中在未來可行的路徑上。
>   * social attention：學習agent（行人）之間的interaction，以及這些互動對未來路徑的影響。
> 3. **LSTM based GAN module**：利用對抗式學習為每一個agent產生一系列realistic的路徑。

* 簡單來說就是這樣><，對細部的數學模型有興趣的可以去看看paper。  
  也可以看看我以前做的[簡報](https://drive.google.com/file/d/13IOqA-kj9Ff-p14wcTSfturLvnW9WO2V/view?usp=sharing)。

## Experiments
### Performance
* 來看一下他的表現（ADE/FDE）～～～
![performace](https://raw.githubusercontent.com/fumchin/myblog/master/assets/images/post_images/papers/Sophie/performance.png)
其中也做了ablation study（把model的部份拿掉，留下特定的部份，看看成果並分析區塊分別帶來的影響）
> TA：social features + social attention  
> TO + IO：拿掉兩個attention modules  
> TO + IA：只拿掉social attention  
> TA + IO：只拿掉physical attention  
> TA + IO：兩個features跟兩個attention modules都在喔喔喔  
> 結果當然是全部都有的會表現最好，不然分那多區塊又發現沒用不就尷尬了（x） 

### Qualitative Results
* 展示了一些數值上看不見的東西，像是改善了路徑的預測跟注意力的位置（相對於Social GAN），如圖：
  ![vsSocialGAN]()
  以及道路（哪裡可以走）的辨識
  ![road]